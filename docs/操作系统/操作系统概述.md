**操作系统是管理软硬件资源，为程序提供服务的程序。**
### 系统调用：为什么区分内核态和用户态？
保护操作系统自身的安全性、稳定性和可靠性。

- CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用。
- Intel的CPU将特权级别分为4个级别：RING0（最高）,RING1,RING2,RING3（最低）。内核态使用RING0级别，几乎可以访问计算机的任何资源并且不受限制。用户态使用Ring3级别，级别最低。
- 我们运行的程序一般都处于用户态，当程序需要调用操作系统提供的子功能，就需要系统调用。凡是与系统级别资源有关的操作，例如文件操作，进程管理，内存管理等，都必须通过系统调用的方式向操作系统提出申请，将需要进行的操作交由操作系统来代为完成。

<div align=center>
<img src="/assets/img/操作系统.png" width="500">
</div>

### 进程
**为什么需要进程？**

- 进程是系统进行资源分配的基本单位
- 进程作为程序独立运行的载体保障程序正常运行
- 提高操作系统资源的利用率
#### 并发和并行
单核 cpu 下，线程实际还是串行执行的。操作系统中有一个组件叫做任务调度器，将 cpu 的时间片分给不同的程序使用，只是由于 cpu 在线程间（时间片很短）的切换非常快，人类感觉是同时运行的。一般将这种线程轮流使用cpu的做法称为并发。
多核 cpu下，每个核都可以调度运行线程，这时候线程可以是并行的。并发是同一时间间隔多件事情的能力，不一定要同时。并行是同一时间动手做多件事情的能力。
#### 进程、线程、协程

- 我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个运行中的程序，就被称为进程。
- 线程实际上就是进程当中的执行流，多个线程之间共享一个进程的code，data，file，这样每个线程获取资源时代价减小，在内存空间中存储上述资源只需一份而不需要多份。
- 协程是用户态的轻量级线程，是线程内部的基本单位。由用户进行调度，无需线程上下文切换、无需原子操作锁定及同步的开销、方便切换控制流，简化编程模型。
| **区别** | **进程和线程** |
| --- | --- |
| 资源 | 进程是资源分配的基本单位；线程不拥有资源，线程可以访问隶属进程的资源 |
| 调度 | 线程是独立调度的基本单位。一个进程可以有多个线程，多个线程共享进程的资源。在同一进程中线程切换的话不会引起进程的切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程的切换。 |
| 系统开销 | 创建或撤销进程，系统都要分配回收资源，远大于创建或撤销线程的开销；进程切换时，涉及当前进程 CPU 环境保存及新调度进程 CPU 环境设置。线程切换只需保存和设置少量寄存器的内容，开销很小。 |
| 通信 |  线程间可以通过直接读写同一进程的数据进行通信，但是进程通信需要借助一些复杂的方法。 |

#### 进程类型
**僵尸进程：**一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。
僵尸进程是有危害的。因为进程的退出状态必须被维持下去，它要告诉关心它的进程（父进程），你交给我的任务，我办的怎么样了。可父进程如果一直不读取，那子进程就一直处于Z状态。而维护Z状态需要用数据维护，保存在task_struct(PCB)中。PCB本身就是一个结构体会占用空间，僵尸进程会造成资源浪费。
解决方法：

- 通过信号机制：子进程退出时向父进程发送SIGCHILD信号，父进程在信号处理函数中调用wait进行处理僵尸进程。
- kill -9 父进程

**孤儿进程：**一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。孤儿进程由于有init进程循环的wait()回收资源，因此并没有什么危害。
**守护进程：**

- 守护进程是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。
- 守护进程一般在系统启动时开始运行，除非强行终止，否则直到系统关机都保持运行。
- Linux系统的大多数服务器就是通过守护进程实现的。常见的守护进程包括系统日志进程syslogd、 web服务器httpd、邮件服务器sendmail和数据库服务器mysqld等。
- 一个守护进程的父进程是init进程，因为它真正的父进程在fork出子进程后就先于子进程exit退出了，所以它是一个由init继承的孤儿进程。守护进程是非交互式程序，没有控制终端，所以任何输出，无论是向标准输出设备stdout还是标准出错设备stderr的输出都需要特殊处理。
- 守护进程的名称通常以d结尾，比如sshd、xinetd、crond等
#### 进程五种状态
一般说来，一个进程并不是自始至终连续不停地运行的，它与并发运行中的其他进程是相互制约的。
进程状态包括创建状态new、就绪状态ready、运行状态running、阻塞状态waiting、结束状态terminated。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1661397808816-7e65b5c2-f3b6-41f7-ba6f-d261fe6edbdb.png#clientId=u3724f154-8ce9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=172&id=u7e1aef56&margin=%5Bobject%20Object%5D&name=image.png&originHeight=288&originWidth=758&originalType=binary&ratio=1&rotation=0&showTitle=false&size=75093&status=done&style=none&taskId=u44b03007-122b-4b7b-8342-a634c632bf3&title=&width=452)

- 创建状态：一个新进程被创建时的第一个状态；
- 创建状态->就绪状态：当进程被创建完成并初始化后，一切就绪准备运行时，就变为就绪状态，这个过程是很快的；
- 就绪态<->运行态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；运行状态使用完CPU时间片后，又重回就绪态。只有就绪状态和运行状态能互相转化，其他状态之间都是单向转换的。
- 运行态->阻塞态->就绪态：程在运行状态时，因申请系统某种资源（比如打印机资源）或者请求等待某个事件发生，会进入阻塞状态，等拿到资源后或等待的事件发生就会回到就绪状态。进程由运行态->阻塞态是自身做出的主动行为。进程由阻塞态->就绪态是被动发生的。
- 运行态->结束态：当进程已经运行完成后的状态；
#### 进程控制块( PCB ) 
操作系统用来存储有关进程的所有信息的数据结构，用于存储每个进程的信息。操作系统通过PCB来控制和管理进程，PCB是系统感知进程存在的唯一标志。
![](https://cdn.nlark.com/yuque/0/2022/png/26499320/1646834700832-2db755c3-c8a2-485e-aae4-b5219e1af807.png#clientId=u74f5dcb3-32d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=287&id=u5291d2ef&margin=%5Bobject%20Object%5D&originHeight=586&originWidth=1321&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u7865a1f4-2cda-4f6b-ae67-9aea946af8d&title=&width=646)
**创建进程**

- 为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB
- 为进程分配资源，如果资源不足，进程就会进入等待状态，以等待资源；
- 初始化 PCB
- 如果进程的调度队列能够接纳新进程，那就将进程插入到就绪队列，等待被调度运行；

**终止进程**

- 查找需要终止的进程的 PCB；
- 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；
- 如果其还有子进程，则应将其所有子进程终止；
- 将该进程所拥有的全部资源都归还给父进程或操作系统；
- 将其从 PCB 所在队列中删除；

**阻塞进程：**当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，只能由另一个进程唤醒。

- 找到将要被阻塞进程标识号对应的 PCB；
- 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；
- 将该 PCB 插入到阻塞队列中去；

**唤醒进程**

- 在该事件的阻塞队列中找到相应进程的 PCB；
- 将其从阻塞队列中移出，并置其状态为就绪状态；
- 把该 PCB 插入到就绪队列中，等待调度程序调度；

#### 进程间通信与同步
进程同步就是控制多个进程按一定顺序执行，而进程间通信（IPC）是在进程间传输信息。它们之间的关系是：进程通信是一种手段，而进程同步是一种目的，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

- **管道**分为命名管道和匿名管道，命名管道可以用于两个或任意多个进程间通信，匿名管道则只能用于有血缘关系（父子进程、兄弟进程、爷孙进程等）的进程间通信。Linux中的“|”命令就是匿名管道，表示把一个进程的输出作为另一个进程的输入。管道就是内核里的一段缓存，从管道一端写入的数据实际上是缓存在内核中，从另一端读取也就是从内核中读取这段数据。管道是半双工的，数据只能向一个方向流动，双方需要互相通信时，需要建立起两个管道。
- **共享内存**就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的一种IPC方式，因为没有内存拷贝的操作，但需要依靠互斥锁或信号量来实现同步。
- **信号**是Linux系统中的进程间通信方式，信号可以在任何时候发给某一进程，用于通知该进程某个事件已经发生。比如kill -9命令就可以向指定的进程发送一个终止信号从而杀死进程。
- **信号量**本质就是一个计数器，记录资源能被多少个进程同时访问，用来实现进程之间的互斥与同步，信号量的引入的是为了解决共享内存通信方式造成的进程安全问题。
- **消息队列：**多个不相干的进程可以通过一个消息队列来传递数据，且传递的是一个有意义的数据结构，而管道只能传递没有意义的字节流，还需要在接收端做解析。消息队列和管道一样是有一个buffer size限制的，当buffer size 为空或为满的时候，send和receive会sleep。
- **Socket：**可用于不同主机之间的进程间通信。
#### 进程调度算法
进程调度是指计算机通过决策觉得哪个就绪进程可以获得CPU使用权。
**进程调度步骤：**

- 保留旧进程的运行信息，请出旧进程（收拾包袱）
- 选择新进程，准备运行环境并分配CPU（新进驻）

**进程调度三种机制：**

- 就绪队列的排队机制：将就绪进程按照一定方式排成队列，以便调度程序可以最快找到就绪进程
- 选择运行进程的委派机制：调度程序以一定的策略选择就绪进程，将CPU资源分配给它。
- 新老进程的上下文切换进制：保存当前进程的上下文信息，装入被委派执行进程的运行上下文

**非抢占式调度算法：**

- 处理器一旦分配给某个进程，就让该进程一直使用下去。
- 调度程序不以任何原因抢占正在被使用的处理器。
直到进程完成工作或因为IO阻塞才会让出处理器

**强占式调度算法：**

- 调度程序以一定的策略暂停当前进程的运行
- 保存好旧进程的上下文信息，分配处理器给新进程
|  | 抢占式调度 | 非抢占式调度 |
| --- | --- | --- |
| 系统开销 | 频繁切换，开销大 | 切换次数少，开销小 |
| 公平性 | 相对公平 | 不公平 |
| 应用 | 通用系统 | 专业系统 |

不同环境的调度算法目标不同，所以对不同的环境需要使用不同的调度算法。
**批处理系统**：批处理系统没有太多的用户操作，在该系统中，调度算法的目标是保证吞吐量和周转时间（从进程提交到进程终止）。批处理系统适用非抢占式调度算法。

- **先来先服务FCFS**(first-come first-serverd)：每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。这种调度方式有利于长作业，不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，造成短作业等待时间过长。
- **最短作业优先**SJF(shortest job first)：优先选择从就绪队列中估计运行时间最短的进程，不利于长作业进程的执行
- **最短剩余时间优先**SRTF(Shortest Remaining Time First)：最短作业优先的抢占版本，按照剩余运行时间的顺序来进行调度，当一个新的作业到达时，其整个运行时间与当前运行的进程剩余时间做比较，如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。

**交互式系统**：有大量的用户交互操作，在该系统中调度算法的目标时快速的进行响应，用强占式调度算法。

- **时间片轮转调度**
   - 将所有就绪进程按照**FCFS的原则排成一个队列**，每次调度时，把CPU时间分配给队头进程，该进程执行一个时间片后，将有计时器发出时钟中断，调度程序便停止该进程的执行，并把它送往就绪队列的末尾，同时继续把CPU时间分配给队头的进程。
   - 时间片轮转算法的效率和时间片的大小有很大的关系。因为进程切换都要保存进程的信息并且载入新进程的信息，**如果时间片太小，会导致进程切换频繁**，在进程切换上就会花费时间太多。**如果时间片过长，那么将退化为FCFS调度**。
- **优先级调度算法**：为每个进程都分配一个优先级，按照优先级的顺序进行调度，为了防止低优先级的进程永远得到不调度，可以随着时间增加等待进程的优先级
- **多级反馈队列调度**：多级队列是为了这种需要连续执行多个时间片的进程考虑。
   - 设置多个队列，每个队列不优先级不同，优先级越高时间片越短。
   - 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
   - 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

![](http://cdn.processon.com/6294432a5653bb788c7ff354?e=1653887290&token=trhI0BY8QfVrIGn9nENop6JAc6l5nZuxhjQ62UfM:-xY7iq3hG-5flficCvvMnxkH10c=#crop=0&crop=0&crop=1&crop=1&height=281&id=GhVuP&originHeight=650&originWidth=878&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=&width=379)
#### 进程互斥
一个时间段内只允许一个进程使用的资源称为临界资源。许多物理设备（比如摄像头、打印机）都属于临界资源。此外还有许多变量、数据、内存缓冲区等都属于临界资源。对临界资源的访问, 必须互斥地进行。
**进程互斥**指当一个进程访问某临界资源时, 另一个想要访问该临界资源的进程必须等待。当前访问临界资源的进程访问结束, 释放该资源之后, 另一个进程才能去访问临界资源。
临界区是进程中访问临界资源的代码段。
**信号量：**信号量就是一个变量（可以是一个整数, 也可以是更复杂的记录型变量）可以用一个信号量来表示系统中某种资源的数量。信号量有两种操作：

- P操作：将s减1，相减后，如果s<0，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；
- V操作：将s加1，相加后，如果s<=0，唤醒一个等待中的进程/线程，表明 V 操作不会阻塞；

P操作是用在进入临界区之前，V操作是用在离开临界区之后，这两个操作是必须成对出现的。
**使用信号量进行互斥访问：**

- 为共享资源设置一个信号量s，其初值为1，表示该临界资源未被占用。
- A线程进入临界区前执行P操作，s值变为0，表示临界资源为空闲，该线程可进入临界区。
- B线程来了之后，s值变为-1表示临界资源已被占用，B线程被阻塞。
- 直到A线程执行V操作s值变为0，释放临界资源，才唤醒B线程

**生产者消费者问题**：生产者在生成数据后，放在一个缓冲区中；消费者从缓冲区取出数据处理；任何时刻，只能有一个生产者或消费者可以访问缓冲区；
**解决方法：**
互斥信号量 `mutex`用于互斥访问缓冲区，初始化值为 1；资源信号量** **`emptyBuffers`用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）；资源信号量 `fullBuffers`用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）；

- 如果消费者线程一开始执行 P(fullBuffers)，由于信号量 fullBuffers 初始值为 0，则此时 fullBuffers 的值从 0 变为 -1，说明缓冲区里没有数据，消费者只能等待。
- 生产者执行 P(emptyBuffers)，表示减少 1 个空槽，如果当前没有其他生产者线程在临界区执行代码，那么该生产者线程就可以把数据放到缓冲区，放完后，执行 V(fullBuffers) ，信号量 fullBuffers 从 -1 变成 0，表明有「消费者」线程正在阻塞等待数据，于是阻塞等待的消费者线程会被唤醒。
- 消费者线程被唤醒后，如果此时没有其他消费者线程在读数据，那么就可以直接进入临界区，从缓冲区读取数据。最后，离开临界区后，把空槽的个数 + 1。

**管程：**解决信号量在临界区的 PV 操作上的配对的麻烦，把配对的 PV 操作集中在一起，生成的一种并发编程方法。其中使用了条件变量这种同步机制。所谓管程Monitor，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。用Java语言来形容就是管理类的成员变量和成员方法，让这个类是线程安全的。
那管程是怎么管的呢？在管程的发展史上，先后出现过三种不同的管程模型，现在广泛应用的是 MESA 模型，Java管程的实现参考的也是此模型。
管程和信号量关于互斥的实现完全一样，都是将共享变量及其操作统一封装起来。
#### 死锁
死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。
**四个必要条件**：

- 互斥：一个资源每次只能被一个进程使用（资源独立）
- 请求与保持：一个进程因请求资源而阻塞时，对已获得的资源保持不放（不释放锁）
- 不剥夺：进程已获得的资源，在未使用之前，不能强行剥夺（抢夺资源）
- 循环等待：若干进程之间形成一种头尾相接的循环等待的资源关闭（死循环）

**避免死锁方法**
从形成死锁的条件入手，破坏形成死锁的四个条件中的一个或多个，保证系统不会进入死锁状态。

- 破坏互斥条件：比如只读文件、磁盘等软硬件资源可采用这种办法处理。
- 破坏请求与保持条件 ：在进程开始执行之前，就把其要申请的所有资源全部分配给他，直到所有资源都满足，才开始执行。
- 破坏不剥夺条件 ：允许进程强行从资源占有者那里夺取某些资源
- 破坏 "循环等待" 条件：给系统的所有资源编号，规定进程请求所需资源的顺序必须按照资源的编号依次执行。
### 虚拟内存
虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。
为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令（**页面置换**）。
很多时候我们使用点开了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存。**为什么可以这样呢？** 正是因为虚拟内存的存在，通过 虚拟内存 可以让程序可以拥有超过系统物理内存大小的可用内存空间。另外，虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）。这样会更加有效地管理内存并减少出错。
**虚拟内存**是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。不要单纯认为虚拟内存只是“使用硬盘空间来扩展内存“的技术。虚拟内存的重要意义是它定义了一个连续的虚拟地址空间，并且 把内存扩展到硬盘空间。
**虚拟地址和物理地址**
虚拟地址（逻辑地址）由操作系统决定。物理地址指的是真实物理内存中地址，是内存单元真正的地址。CPU 通过内存管理单元MMU将虚拟地址转换成物理地址。 
如果没有虚拟地址空间，程序直接访问操作的都是物理内存，存在着以下两个问题：

- 用户程序可以随意的访问任意的物理内存所导致的安全性问题
- 如果想要同时运行多个程序特别困难，如果多个进程同时直接访问一个物理地址，就会导致进程崩溃。
#### 分段和分页
**连续内存分配**管理是指为一个用户进程分配一块连续的内存空间。例如分块是把内存分为几个大小相等且固定的块，每个进程占用其中一个，如果进程很小的话，会浪费大量的空间，已经淘汰！
**非连续内存分配**允许一个程序使用的内存分布在离散或者说不相邻的内存中，包括分段和分页。
**分段**：程序是由若⼲个逻辑片段组成的，如主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 。 不同的段是有不同的属性，⽤分段的形式把这些段分离出来。
**分段机制下，虚拟地址和物理地址是如何映射的？**
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1651130479177-d90f47c2-5a53-409e-a076-ebf179ce3a08.png#clientId=u05c56de5-12ad-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=328&id=u7d4d0061&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1004&originWidth=1382&originalType=binary&ratio=1&rotation=0&showTitle=false&size=80486&status=done&style=none&taskId=ud64c3948-2f64-45ed-8894-64d612a2278&title=&width=451)
分段机制下的虚拟地址由两部分组成，**段选择子**和**段内偏移量**。

- **段选择子**就保存在段寄存器里面。段选择子里面最重要的是**段号**，用作段表的索引。**段表**里面保存的是这个**段的基地址、段的界限和特权等级**等。
- 虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个
项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1651138274175-a5e18e2a-1906-4a74-9ff0-89b51d236dc7.png#clientId=u05c56de5-12ad-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=252&id=k8i0v&margin=%5Bobject%20Object%5D&name=image.png&originHeight=651&originWidth=1055&originalType=binary&ratio=1&rotation=0&showTitle=false&size=80863&status=done&style=none&taskId=u0f7ddb9d-f2ad-44d9-863e-b5ce17a0a0c&title=&width=408.5)
分段的好处就是能产⽣连续的内存空间，但是会出现内存碎⽚和内存交换效率低的问题。
**为什么分段会产生内存碎片的问题？**假设有 1G 的物理内存，用户执行了多个程序如下图所示，这时如果我们关闭了浏览器，空闲内存还有256MB，如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1651138674814-db713953-32cf-4ecf-89b0-7541ddc29c7c.png#clientId=u05c56de5-12ad-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=217&id=ud8599c7c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=806&originWidth=1518&originalType=binary&ratio=1&rotation=0&showTitle=false&size=306259&status=done&style=none&taskId=uc8ee94f2-547b-43a5-af33-739c8b51352&title=&width=409)
**分页**是把整个虚拟和物理内存空间切成⼀段段固定尺⼨的⼤⼩ ，这样一个连续并且尺寸固定的内存空间称为页。在 Linux 下，每⼀⻚的⼤⼩为 4KB。虚拟地址与物理地址之间通过页表来映射。页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1651139257736-fe09bc46-0b94-4f7c-b9ed-45bc11b9c434.png#clientId=u05c56de5-12ad-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=215&id=u0bbea839&margin=%5Bobject%20Object%5D&name=image.png&originHeight=561&originWidth=935&originalType=binary&ratio=1&rotation=0&showTitle=false&size=59913&status=done&style=none&taskId=u0a88d51b-bf27-4dea-935a-0494e70dd72&title=&width=358.5)
**分页是怎么解决分段的内存碎片、内存交换效率低的问题？**
分页式管理将程序资源划分为固定大小的页，将每一个虚拟页映射到物理页之中，由于每个页是固定大小的，操作系统可以整齐的分配物理内存空间，避免产生了外部碎片。
分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。****分页机制下，虚拟地址和物理地址是如何映射的？**
在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。具体步骤：

- 把虚拟内存地址，切分成页号和偏移量；
- 根据页号，从页表里面，查询对应的物理页号；
- 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1651139842440-427614e9-1626-4877-9e86-6b3d9f3c0f4c.png#clientId=u05c56de5-12ad-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=264&id=uc8204f57&margin=%5Bobject%20Object%5D&name=image.png&originHeight=797&originWidth=1067&originalType=binary&ratio=1&rotation=0&showTitle=false&size=53249&status=done&style=none&taskId=ue8bf0e45-a06e-4a5d-ba53-2a1727e6468&title=&width=353.5)
**分页存在的问题**：空间占用大。在 Linux中，可以并发的执行多个进程，而每个进程都有其自己的虚拟内存空间，那么也自然都有自己独有的页表。在32位Linux系统下，虚拟内存空间的大小为4G（2^32），而每页的大小为4K（2^12）,至少有2^20个内存页，倘若每个页表项为4Byte，那么每个页表大小也至少为4M。
若有100个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。
**分页和分段区别**
共同点： 

- 都是离散分配的，每个页和每个段的内存是连续的。 
- 都是为了提高内存利用率，减少内存碎片。 

不同点： 

- 分页式管理的页面大小是固定的，由操作系统决定；分段式管理的页面是由用户程序所决定的。 
- 分页是为了满足操作系统内存管理的需求，每一页是没有实际的意义的；而段是有逻辑意义的，在程序中可认为是代码段、数据段。 
- 分页的内存利用率高，不会产生外部碎片；而分段如果单段长度过大，为其分配很大的连续空间不方便，会产生外部碎片。
#### 多级页表
在分页内存管理中，每个进程都是有自己的虚拟地址空间，也就说都有自己的页表，会存在页表内存占用大的问题？参考答案：[https://zhuanlan.zhihu.com/p/152119007](https://zhuanlan.zhihu.com/p/152119007)
引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。为了提高内存的空间性能，提出了多级页表的概念；
**多级页表**是将一级页表再进行分页，分成1024个二级页表，并且每个二级页表中存有1024个页表项，形成如下的二级分页的结构。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1661401113289-70e53200-8f53-4931-abac-f5fcca52a5ba.png#clientId=u3724f154-8ce9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=290&id=ud3bccdd7&name=image.png&originHeight=1146&originWidth=1686&originalType=binary&ratio=1&rotation=0&showTitle=false&size=180356&status=done&style=none&taskId=uf0a4a729-2c05-40ac-a66e-fc1bfa0b19e&title=&width=426)
每个进程都有 4GB 的虚拟地址空间，如果4GB的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了。但是实际上对于大多数程序来说，其使用到的空间远未达到 4G，所以会存在部分对应的页表项都是空的，根本没有分配。而对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。
如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB，这比单级页表的 4MB大大节约了内存。
那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。
**快表**
为了解决虚拟地址到物理地址的转换速度，在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为页表缓存、转址旁路缓存、快表。
有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1651148474806-4273c26f-077a-4cf7-905c-3c05714c7c83.png#clientId=u05c56de5-12ad-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=255&id=u18172c87&margin=%5Bobject%20Object%5D&name=image.png&originHeight=509&originWidth=1008&originalType=binary&ratio=1&rotation=0&showTitle=false&size=39241&status=done&style=none&taskId=u7c71cc14-c91a-45c0-a8a6-1ee5c833e59&title=&width=504)
**段页式：**结合了段式管理和页式管理的优点，把主存先分成若干段，每个段又分成若干页，也就是说段页式管理机制中段与段之间以及段的内部的都是离散的
#### [内存页面置换算法](https://xiaolincoding.com/os/5_schedule/schedule.html#%E5%86%85%E5%AD%98%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95)

#### 虚拟内存实现
虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。

- 请求分页存储管理

建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。

- 请求分段存储管理

建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。

- 请求段页式存储管理

**请求分页与分页存储管理的区别**
请求分页存储管理建立在分页管理之上。他们的根本区别是是否将程序全部所需的全部地址空间都装入主存，这也是请求分页存储管理可以提供虚拟内存的原因
不管用上面哪种实现方式，实现虚拟内存技术都需要：

- **一定容量的内存和外存**：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了。
- **缺页中断**：如果需要执行的指令或者访问的数据尚未在内存当中（称为缺页或者缺段），则由处理器通知操作系统将相应的页面调入内存，继续执行程序
- **虚拟地址空间**：逻辑地址到物理地址的转化
### IO模型
**同步**：用户线程发起IO请求后需要等待和轮询内核IO操作完成后才能执行。
**异步**：用户线程发起IO请求后仍然可以执行，当内核IO操作完成后通知用户线程，或者调用用户线程注册的回调函数。
同步与异步描述的是线程之间的关系，两个线程之间要么是同步的，要么是异步的。
同步操作时，调用者需要等待被调用者返回结果，才会进行下一步操作。
异步是调用者不需要等待被调用者返回调用，即可进行下一步操作，被调用者通常依靠事件、回调等机制来通知调用者结果。
**阻塞**：I/O操作需要彻底完成后才能返回用户空间。
**非阻塞**：I/O操作被调用后立即返回一个状态值，无需等I/O操作彻底完成。
阻塞与非阻塞是对同一个线程来说的，在某个时刻，线程要么处于阻塞，要么处于非阻塞。
阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态：
阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。
非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1661410427115-9f3fd158-4158-4473-8af8-80cbe5ee41f1.png#clientId=u3724f154-8ce9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=252&id=u0de271dc&name=image.png&originHeight=504&originWidth=844&originalType=binary&ratio=1&rotation=0&showTitle=false&size=166566&status=done&style=none&taskId=uca9a777c-d047-4707-8fad-b97fa102810&title=&width=422)
#### 阻塞IO
用户线程通过系统调用read发起IO读操作，上下文从用户态切换为内核态。CPU先利用DMA控制器将数据从硬盘拷贝到内核空间的缓冲区。然后CPU再将缓冲区中的数据拷贝到用户空间的用户缓冲区。上下文从内核态切换回用户态，read调用执行返回。整个IO请求的过程中，用户线程是被阻塞的，这导致用户在发起IO请求时，不能做任何事情，对CPU的资源利用率不够。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1661411193195-bdf08bf6-162a-4a91-a31e-dfe9b31a080d.png#clientId=u629fe945-cc09-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=266&id=u223bf021&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1076&originWidth=1306&originalType=binary&ratio=1&rotation=0&showTitle=false&size=328099&status=done&style=none&taskId=u0779103f-6835-4966-b40c-3b410ffd132&title=&width=323)
#### 非阻塞IO
用户会一直发起 read 调用，尝试读取socket中的数据，直到读取成功后，才继续处理接收的数据。整个IO请求过程中，虽然每次用户线程每次发起IO请求可以立即返回，但那会死为了等到数据，仍需要不断地轮询、重复请求，消耗大量的CPU资源。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1661411261266-33bb942f-5519-464d-b465-e16a0599ebf9.png#clientId=u629fe945-cc09-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=248&id=u3e8eff09&margin=%5Bobject%20Object%5D&name=image.png&originHeight=562&originWidth=777&originalType=binary&ratio=1&rotation=0&showTitle=false&size=57579&status=done&style=none&taskId=uc0ebf1ac-ddd2-4e6a-b7b8-c760abd7181&title=&width=342.5)
#### I/O多路复用
IO多路复用通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。
**select/poll**实现多路复用的方式是将已连接的 Socket 都放到一个**文件描述符集合**，然后调用select函数将文件描述符集合拷贝到内核里，内核通过遍历文件描述符集合来检查是否有网络事件产生，检查到有事件产生后，将此 Socket 标记为可读或可写，接着把整个文件描述符集合拷贝回用户态。最后用户态再通过遍历找到可读或可写的 Socket，对其处理。 select 使用固定长度的 BitsMap表示文件描述符集合，默认最大值为 `1024`；poll是使用动态数组存储文件描述符集合。 

-  对于 select/poll 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 
-  二者都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。 

![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1661411901689-35d0012b-4b1d-4039-a514-477914f62a75.png#clientId=u629fe945-cc09-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=273&id=uae9a7f26&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1084&originWidth=1316&originalType=binary&ratio=1&rotation=0&showTitle=false&size=347587&status=done&style=none&taskId=uad89d07b-6296-4209-809c-c9665d224ac&title=&width=332)
**epoll **通过两个方面，很好解决了 select/poll 的问题。

- epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 添加到红黑树中，红黑树是个高效的数据结构，增删查一般时间复杂度是 O(logn)，通过对这棵黑红树进行操作，这样就不需要像 select/poll 每次操作时都传入整个 socket 集合，只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。
- epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。

![](https://cdn.nlark.com/yuque/0/2022/png/26499320/1661411946044-4806b485-c99e-43cf-9ca9-fff32b41b7db.png#clientId=u629fe945-cc09-4&crop=0&crop=0&crop=1&crop=1&height=231&id=ZSPC3&originHeight=527&originWidth=1142&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u4a927e2e-475a-4227-b3de-2ed780c62ce&title=&width=500)
#### 触发方式
**边缘触发：**

- 使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；
- 使用边缘触发模式，I/O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I/O 搭配使用，程序会一直执行 I/O 操作，直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK。

**水平触发：**使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；
一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。**select/poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。**
#### 信号驱动IO
当进程发起一个IO操作，会向内核注册一个信号处理函数，然后进程返回不阻塞；当内核数据就绪时会发送一个信号给进程，进程便在信号处理函数中调用IO读取数据。特点：回调机制，实现、开发应用难度大；
#### 异步IO
用户线程发起read调用的同时注册一个回调函数，read 立即返回，等内核将数据准备好后，再调用指定的回调函数完成处理。在这个过程中，用户线程一直没有阻塞。
Note：信号驱动I/O是由内核通知用户进程何时启动一个I/O操作，而异步I/O模型是由内核通知用户进程I/O操作何时完成
### 零拷贝
零拷贝技术指在计算机执行操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而减少上下文切换以及 CPU 的拷贝时间。
#### 传统IO数据读写
在 Linux 系统中，传统的访问方式是通过 write() 和 read() 两个系统调用实现的，通过 read() 函数读取文件到到缓存区中，然后通过 write() 方法把缓存中的数据输出到网络端口。
```
read(file_fd, tmp_buf, len);
write(socket_fd, tmp_buf, len);
```
传统IO数据读写的具体过程：

- 用户进程通过read() 函数向内核发起系统调用，上下文从用户态切换为内核态。
CPU利用DMA控制器将数据从硬盘拷贝到内核空间的缓冲区。DMA直接内存访问，是一种允许外围设备直接访问系统主内存的机制。目前大多数的硬件设备，包括磁盘控制器、网卡、显卡以及声卡等都支持 DMA 技术。
- CPU将缓冲区中的数据拷贝到用户空间的用户缓冲区。上下文从内核态切换回用户态，read 调用执行返回。
- 用户进程通过 write() 函数向内核发起系统调用，上下文从用户态切换为内核态。CPU 将用户缓冲区中的数据拷贝到内核空间的socket缓冲区。
- CPU把用户缓冲区数据拷贝到内核 socket 缓冲区
- CPU 利用 DMA 控制器将数据从网络缓冲区拷贝到网卡进行数据传输。上下文从内核态切换回用户态，write系统调用执行返回。

整个过程涉及 2 次 DMA 拷贝、2 次 CPU 拷贝总共 4 次拷贝，以及 4 次上下文切换。过多的数据拷贝无疑会消耗 CPU 资源，大大降低了系统性能。
![](https://cdn.nlark.com/yuque/0/2022/webp/26499320/1661413093610-a4a0f49b-8356-4bcb-9f91-4016c7ad453e.webp#clientId=u91d6ccc8-eb5a-4&crop=0&crop=0&crop=1&crop=1&height=250&id=AxjYJ&originHeight=678&originWidth=1100&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u10a2cefd-f045-4d04-bec5-e8e140341cf&title=&width=405)
#### 用户态直接 I/O
用户态直接 I/O 使得应用进程或运行在用户态下的库函数直接访问硬件设备，数据直接跨过内核进行传输，内核在数据传输过程除了进行必要的虚拟存储配置工作之外，不参与任何其他工作，这种方式能够直接绕过内核，极大提高了性能。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1661413291398-2b9a1671-81b9-4c39-8283-98a72f1a1a02.png#clientId=u91d6ccc8-eb5a-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=258&id=u7e624d41&name=image.png&originHeight=515&originWidth=808&originalType=binary&ratio=1&rotation=0&showTitle=false&size=113047&status=done&style=none&taskId=u3c7d70af-33db-4d00-b021-609267e330a&title=&width=404)
#### 减少数据拷贝次数
**DMA直接内存访问**是一种允许外围设备直接访问系统主内存的机制。目前大多数的硬件设备，包括磁盘控制器、网卡、显卡以及声卡等都支持 DMA 技术。
**1.mmap+write减少1次CPU拷贝**
使用 mmap + write 代替原来的 read + write 方式，减少了 1 次 CPU 拷贝操作。mmap目的是将内核中读缓冲区的地址与用户空间的缓冲区进行映射，从而实现内核缓冲区和应用程序内存的恭喜，省去了将数据从内核读缓冲区拷贝到用户缓冲区的过程。整个拷贝过程会发生 4 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝
```
tmp_buf = mmap(file_fd, len);
write(socket_fd, tmp_buf, len);
```

- 用户进程通过 mmap() 函数向内核发起系统调用，上下文从用户态切换为内核态。
将用户进程的内核空间的读缓冲区与用户空间的缓存区进行内存地址映射。
- CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间的读缓冲区。上下文从内核态切换回用户态，mmap 系统调用执行返回。
- 用户进程通过 write() 函数向内核发起系统调用，上下文从用户态切换为内核态。PU将读缓冲区中的数据拷贝到的网络缓冲区。
- CPU利用DMA控制器将数据从网络缓冲区拷贝到网卡进行数据传输。上下文从内核态切换回用户态，write 系统调用执行返回。

![](https://cdn.nlark.com/yuque/0/2022/webp/26499320/1661413344813-83c4efc4-3fe1-4c88-8414-085936f54ba9.webp#clientId=u91d6ccc8-eb5a-4&crop=0&crop=0&crop=1&crop=1&height=253&id=HsGx2&originHeight=677&originWidth=1100&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=uab167f9c-2f4e-43d2-b418-2c08dbfe514&title=&width=411)
**2.sendfile再减少一次系统调用**
基于 sendfile 系统调用的零拷贝方式可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，减少一次系统调用。整个拷贝过程会发生 2 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝，用户程序读写数据的流程如下：

- 用户进程通过 sendfile() 函数向内核发起系统调用，上下文从用户态切换为内核态）。CPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间的读缓冲区。
- CPU 将读缓冲区中的数据拷贝到的网络缓冲区。
- CPU 利用 DMA 控制器将数据从网络缓冲区拷贝到网卡进行数据传输。上下文从内核态切换回用户态，sendfile 系统调用执行返回。

![](https://cdn.nlark.com/yuque/0/2022/webp/26499320/1661413461180-8d58beae-832e-4b6d-ac11-5af06febf978.webp#clientId=u91d6ccc8-eb5a-4&crop=0&crop=0&crop=1&crop=1&height=291&id=ei9gp&originHeight=686&originWidth=1100&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=uddc2aa06-434c-4c7a-87a5-7457aee43ad&title=&width=466)
**3.sendfile + DMA gather copy再减少一次CPU拷贝**
基于 sendfile + DMA gather copy 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换、0 次 CPU 拷贝以及 2 次 DMA 拷贝，用户程序读写数据的流程如下：

- 用户进程通过 sendfile() 函数向内核发起系统调用，上下文从用户态切换为内核态。CPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间的读缓冲区。
- CPU 把读缓冲区的文件描述符和数据长度拷贝到网络缓冲区。
- 基于已拷贝的文件描述符和数据长度，CPU 利用 DMA 控制器gather/scatter 操作直接批量地将数据从内核的读缓冲区拷贝到网卡进行数据传输。上下文从内核态切换回用户态，sendfile系统调用执行返回。

![](http://cdn.processon.com/627df2e76376890bfe608fa7?e=1652424952&token=trhI0BY8QfVrIGn9nENop6JAc6l5nZuxhjQ62UfM:_Ktga1FUOudqrvbWkLko65ZfsIU=#crop=0&crop=0&crop=1&crop=1&height=248&id=lV17B&originHeight=686&originWidth=1160&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=&width=420)
#### 写时复制
在某些情况下，内核缓冲区可能被多个进程所共享，如果某个进程想要这个共享区进行 write 操作，由于 write 不提供任何的锁操作，那么就会对共享区中的数据造成破坏，写时复制的引入就是 Linux 用来保护数据的。
写时复制指的是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么就需要将其拷贝到自己的进程地址空间中。这样做并不影响其他进程对这块数据的操作，每个进程要修改的时候才会进行拷贝，所以叫写时拷贝。这种方法在某种程度上能够降低系统开销，如果某个进程永远不会对所访问的数据进行更改，那么也就永远不需要拷贝。
### 上下文切换
大多数操作系统都是多任务，通常支持大于 CPU 数量的任务同时运行。实际上，这些任务并不是同时运行的，只是因为系统在很短的时间内，让各个任务分别在 CPU 运行，于是就造成同时运行的错觉。上下文是指某一时刻，寄存器保存了CPU的指令，程序计数器存储了即将执行的下一条指令地址。它们是 CPU 在运行任何任务前，必须依赖的环境。注意：系统调用过程通常称为特权模式切换，而不是上下文切换，系统调用属于同一个进程内的 CPU 上下文切换。
**进程上下文切换**
进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，进程的上下文不仅包括了内核堆栈、寄存器等内核空间的状态，还包括了虚拟内存、栈、全局变量等用户空间的资源。
通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1651245893340-61b2d3f2-9dc4-4391-958b-b5ce698b1154.png#clientId=u27a7ce37-57f4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=96&id=sYVdb&margin=%5Bobject%20Object%5D&name=image.png&originHeight=191&originWidth=870&originalType=binary&ratio=1&rotation=0&showTitle=false&size=27125&status=done&style=none&taskId=u61fdbc63-33f8-454b-a8a3-b49ae8e38b2&title=&width=435)
**发生进程上下文切换的场景**

1. 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。
2. 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。
3. 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。
4. 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行
5. 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

**线程上下文切换**
线程是调度的基本单位，而进程则是资源拥有的基本单位。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。
**发生线程上下文切换的场景：**

- 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。切换线程，CPU 的各种寄存器都要重新刷一遍，从这个角度而言，你可以把进程和线程当作一种东西，只是共享度不同，其他没区别的。
- 前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，内存命中率会高一些，只需要切换线程的私有数据、寄存器等不共享的数据。

虽然同为上下文切换，但同进程内的线程切换，要比多进程间的切换消耗更少的资源，这也正是多线程代替多进程的一个优势。
### 操作系统启动过程
参考资料：[https://blog.51cto.com/u_12302225/2638803](https://blog.51cto.com/u_12302225/2638803)
**1. 上电自检**
上电后，系统开始开机自检，该过程主要对计算机各种硬件设备进行检测，如CPU、内存、主板、硬盘等，如果出现致命故障则停机，并且由于初始化过程还没完成，所以不会出现任何提示信号；如果出现一般故障则会发出声音等提示信号，等待故障清除；若未出现故障，加电自检完成。
2.**加载主引导记录/扇区MBR**
自检完成后，BIOS按照设定的启动顺序依次扫描可启动设备，找到可启动的设备后，去该设备的第一个扇区中读取MBR（Master Boot Record）。MBR是硬盘的0柱面、0磁头、1扇区称为称为主引导扇区。它由三个部分组成，主引导程序(Bootloader)、硬盘分区表 DPT（Disk Partition table）和硬盘有效标志。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1651051251284-238dd85a-84c5-4b77-8f2b-8b79144a7dc0.png#clientId=u11c1bbc7-1aa4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=248&id=kjDMJ&margin=%5Bobject%20Object%5D&name=image.png&originHeight=393&originWidth=577&originalType=binary&ratio=1&rotation=0&showTitle=false&size=75065&status=done&style=none&taskId=u1bc3b1e1-9ca2-4220-bdcb-b0ea636d84e&title=&width=364.5)
**3.Boot Loader启动引导阶段**
CPU把MBR读取至内存运行Boot Loader，Boot Loader会把内核加载到内存去执行。Linux一般使用的是BootLoader是grub。GRUB程序加载执行并引导kernel（内核）程序，包括三个阶段：

- 阶段1：运行系统安装时预先写入到MBR的Bootloader程序—存放在MBR的前446字节里的程序。阶段1任务是读取（加载）硬盘的0柱面，0磁道，2扇区的内容（/boot/grub/stage1）并执行。
- 阶段1.5：是阶段1和阶段2的桥梁，功能是加载阶段2所在分区的文件系统驱动，让阶段1中的bootloader能识别阶段2所在分区的文件系统，此后grub程序便有能力去访问/boot/grub/stage2。
- 阶段2：读取并解析grub的配置文件/boot/grub/grub.cnf，根据配置文件加载内核镜像到内存中，通过initrd程序建立虚拟根文件系统，最后调用（转交）内核。

**4.内核引导阶段**
加载内核，启动一些最核心的程序。为了让内核足够的轻小，硬件驱动并没放在内核文件里面。系统仅加载真正的根文件系统所在设备的驱动程序，以只读方式挂载根文件系统，运行用户空间的第一个应用程序：/sbin/init。
**5.系统初始化阶段**
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1651059316474-6465623a-28db-46b1-828b-ff29081c02b5.png#clientId=u11c1bbc7-1aa4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=308&id=XhvFG&margin=%5Bobject%20Object%5D&name=image.png&originHeight=615&originWidth=1207&originalType=binary&ratio=1&rotation=0&showTitle=false&size=77511&status=done&style=none&taskId=u1abd5a91-2a8f-4d49-861c-02fe9dbac16&title=&width=603.5)
**6.启动终端**
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1651059621671-99dc8f29-ead7-4a78-8f06-6c9e27b00d37.png#clientId=u11c1bbc7-1aa4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=182&id=mhf3D&margin=%5Bobject%20Object%5D&name=image.png&originHeight=363&originWidth=1590&originalType=binary&ratio=1&rotation=0&showTitle=false&size=276158&status=done&style=none&taskId=u744b41dd-b441-4314-98cf-00dd00a175e&title=&width=795)
### CPU执行程序过程
冯诺依曼模型：**CPU**(**控制器、运算器、寄存器)、存储器、输入设备、输出设备**
![image.png](https://cdn.nlark.com/yuque/0/2022/png/26499320/1651122261881-e9ef6668-b6db-483f-b628-4ecbaee25aac.png#clientId=uf6e48dec-3e30-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=284&id=Nokqx&margin=%5Bobject%20Object%5D&name=image.png&originHeight=567&originWidth=829&originalType=binary&ratio=1&rotation=0&showTitle=false&size=82882&status=done&style=none&taskId=u2863951e-7c48-4df5-94db-7834713596c&title=&width=414.5)
CPU中央处理器，32位CPU一次可以计算4个字节0～2^32-1范围内的数值。CPU中的控制器负责控制 CPU 工作。运算器负责计算。寄存器分为多种类，每种寄存器的功能又不尽相同。常见的寄存器种类：

- 通用寄存器，存储需要进行运算的数据。
- 程序计数器，存储要执行的下一条指令的内存地址。
- 指令寄存器，存放程序计数器指向的指令，指令被执行完成之前，指令都存储在这里。

程序和数据都是存储在（存储器）内存中。CPU通过总线和内存记忆其他设备进行通信。总线分为三种：

- 地址总线，用于指定 CPU 将要操作的内存地址；
- 数据总线，用于读写内存的数据；
- 控制总线，用于发送和接收信号，比如中断、设备复位等信号。

程序实际上是一条一条指令。一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。
