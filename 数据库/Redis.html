<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>ivem</title>
    <meta name="generator" content="VuePress 1.9.7">
    
    <meta name="description" content="描述">
    
    <link rel="preload" href="/vblog/assets/css/0.styles.8122b943.css" as="style"><link rel="preload" href="/vblog/assets/js/app.b753b481.js" as="script"><link rel="preload" href="/vblog/assets/js/3.a14ab248.js" as="script"><link rel="preload" href="/vblog/assets/js/1.82212610.js" as="script"><link rel="preload" href="/vblog/assets/js/21.bbedd2e8.js" as="script"><link rel="prefetch" href="/vblog/assets/js/10.fad53fa2.js"><link rel="prefetch" href="/vblog/assets/js/11.7a399e1c.js"><link rel="prefetch" href="/vblog/assets/js/12.e422a996.js"><link rel="prefetch" href="/vblog/assets/js/13.518d5bae.js"><link rel="prefetch" href="/vblog/assets/js/14.3fc7a80c.js"><link rel="prefetch" href="/vblog/assets/js/15.aa9bb0c5.js"><link rel="prefetch" href="/vblog/assets/js/16.092924c1.js"><link rel="prefetch" href="/vblog/assets/js/17.520a4d4a.js"><link rel="prefetch" href="/vblog/assets/js/18.ab44fe50.js"><link rel="prefetch" href="/vblog/assets/js/19.d9c620e5.js"><link rel="prefetch" href="/vblog/assets/js/20.5e37e059.js"><link rel="prefetch" href="/vblog/assets/js/22.8db0efce.js"><link rel="prefetch" href="/vblog/assets/js/23.efb499f0.js"><link rel="prefetch" href="/vblog/assets/js/24.fd13e6fb.js"><link rel="prefetch" href="/vblog/assets/js/4.b102a469.js"><link rel="prefetch" href="/vblog/assets/js/5.60fa46b8.js"><link rel="prefetch" href="/vblog/assets/js/6.1d6eca70.js"><link rel="prefetch" href="/vblog/assets/js/7.aac51c6a.js"><link rel="prefetch" href="/vblog/assets/js/8.a70a1325.js"><link rel="prefetch" href="/vblog/assets/js/9.943c5bfd.js">
    <link rel="stylesheet" href="/vblog/assets/css/0.styles.8122b943.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-7dd95ae2><div data-v-7dd95ae2><div class="password-shadow password-wrapper-out" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>ivem</h3> <p class="description" data-v-59e6cb88>描述</p> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
          
        <!---->
        2022
      </a></span></div></div> <div class="hide" data-v-7dd95ae2><header class="navbar" data-v-7dd95ae2><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/vblog/" class="home-link router-link-active"><img src="/vblog/assets/img/logo.png" alt="ivem" class="logo"> <span class="site-name">ivem</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/vblog/" class="nav-link"><i class="undefined"></i>
  首页
</a></div><div class="nav-item"><a href="/vblog/Java/" class="nav-link"><i class="undefined"></i>
  Java
</a></div><div class="nav-item"><a href="/vblog/计算机网络/TCPIP体系结构.html" class="nav-link"><i class="undefined"></i>
  计算机网络
</a></div><div class="nav-item"><a href="/vblog/操作系统/操作系统概述.html" class="nav-link"><i class="undefined"></i>
  操作系统
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      数据库
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/vblog/数据库/MySQL.html" class="nav-link"><i class="undefined"></i>
  MySQL
</a></li><li class="dropdown-item"><!----> <a href="/vblog/数据库/Redis.html" class="nav-link"><i class="undefined"></i>
  Redis
</a></li></ul></div></div><div class="nav-item"><a href="/vblog/数据结构与算法/" class="nav-link"><i class="undefined"></i>
  数据结构与算法
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      消息中间件
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/vblog/Kafka.html" class="nav-link"><i class="undefined"></i>
  Kafka
</a></li><li class="dropdown-item"><!----> <a href="/vblog/RPC.html" class="nav-link"><i class="undefined"></i>
  RPC
</a></li></ul></div></div><div class="nav-item"><a href="https://github.com/ivemcel/vblog" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-7dd95ae2></div> <aside class="sidebar" data-v-7dd95ae2><div class="personal-info-wrapper" data-v-1fad0c41 data-v-7dd95ae2><!----> <!----> <div class="num" data-v-1fad0c41><div data-v-1fad0c41><h3 data-v-1fad0c41>7</h3> <h6 data-v-1fad0c41>Articles</h6></div> <div data-v-1fad0c41><h3 data-v-1fad0c41>4</h3> <h6 data-v-1fad0c41>Tags</h6></div></div> <ul class="social-links" data-v-1fad0c41></ul> <hr data-v-1fad0c41></div> <nav class="nav-links"><div class="nav-item"><a href="/vblog/" class="nav-link"><i class="undefined"></i>
  首页
</a></div><div class="nav-item"><a href="/vblog/Java/" class="nav-link"><i class="undefined"></i>
  Java
</a></div><div class="nav-item"><a href="/vblog/计算机网络/TCPIP体系结构.html" class="nav-link"><i class="undefined"></i>
  计算机网络
</a></div><div class="nav-item"><a href="/vblog/操作系统/操作系统概述.html" class="nav-link"><i class="undefined"></i>
  操作系统
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      数据库
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/vblog/数据库/MySQL.html" class="nav-link"><i class="undefined"></i>
  MySQL
</a></li><li class="dropdown-item"><!----> <a href="/vblog/数据库/Redis.html" class="nav-link"><i class="undefined"></i>
  Redis
</a></li></ul></div></div><div class="nav-item"><a href="/vblog/数据结构与算法/" class="nav-link"><i class="undefined"></i>
  数据结构与算法
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      消息中间件
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/vblog/Kafka.html" class="nav-link"><i class="undefined"></i>
  Kafka
</a></li><li class="dropdown-item"><!----> <a href="/vblog/RPC.html" class="nav-link"><i class="undefined"></i>
  RPC
</a></li></ul></div></div><div class="nav-item"><a href="https://github.com/ivemcel/vblog" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88></h3> <!----> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
          
        <!---->
        2022
      </a></span></div></div> <div data-v-7dd95ae2><div data-v-7dd95ae2><main class="page" style="padding-right:0;"><section style="display:;"><div class="page-title"><h1 class="title"></h1> <div data-v-8a445198><!----> <!----> <!----> <!----></div></div> <div class="theme-reco-content content__default"><p>Redis(Remote Dictionary Server)远程字典服务器是一个用C语言编写的、开源的、基于内存运行并支持持久化的、高性能的NoSQL数据库。Redis中的数据大部分数据都是存储中内存中的，适合存储频繁访问、数据量小的数据。
Redis客户端是一个程序，通过网络连接到Redis服务器，从而实现跟 Redis服务器的交互。Redis客户端发送命令，同时显示Redis服务器的处理结果。redis-cli（Redis Command Line Interface）是Redis自带的基于命令行的Redis客户端，用于与服务端交互，我们可以使用该客户端来执行redis的各种命令。
Redis默认使用16个库，从0到15。在redis.conf文件中databases 16，可以修改数据库的个数，理论上可以配置无限多个。
<strong>Redis为什么这么快？</strong></p> <ul><li>基于内存：redis使用内存存储数据，读写速度快。</li> <li>单线程实现（ Redis 6.0以前）：redis的命令执行核心模块是单线程的，避免了多个线程切换和锁资源竞争的开销。</li> <li>高效的数据结构：redis的数据结构非常简单，操作节省时间</li></ul> <p>redis的命令执行核心模块是单线程的，但是整个redis实例并不全是单线程的。redis的作者说在实际的应用场景中，很少遇到速度瓶颈在于CPU的情况，往往是网络的带宽和内存的大小限制了redis的性能。
<strong>Redis和memcached的区别？</strong></p> <ul><li>最主要的区别，Redis提供多种数据类型，而memcached只能存储字符串。</li> <li>redis支持持久化，而memcachedd没有持久化策略。这就决定了redis具备一定的容灾机制，但是memcached没有。</li></ul> <h3 id="数据类型"><a href="#数据类型" class="header-anchor">#</a> 数据类型</h3> <h4 id="字符串string"><a href="#字符串string" class="header-anchor">#</a> 字符串String</h4> <p>String 是最基本的 key-value 结构，key 是唯一标识，value 是具体的值。value其实不仅是字符串，也可以是数字（整数或浮点数），value 最多可以容纳的数据长度是 512M。
Redis是用C语言实现的，但是C语言的字符串存在如下缺陷：</p> <ul><li>C语言获取字符串长度的时间复杂度是 O(N)。遍历字符数组中的每一个字符，并进行计数，等遇到字符为 &quot;\0&quot;后，就会停止遍历，返回已经统计到的字符个数。</li> <li>字符串的结尾是以 &quot;\0&quot;字符标识，字符串里面不能包含有 &quot;\0&quot;字符，因此不能保存二进制数据。</li> <li>字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止。</li></ul> <p><strong>底层实现：<strong>redis作者封装了一个名为</strong>简单动态字符串SDS</strong>的数据结构来表示字符串。SDS结构实现：Redis3.0中，SDS中有int len、int free、char buf[]三个属性。len保存字符串的长度，free表示buf数组中未使用的字节数量，buf数组则是保存字符串的每一个字符元素。相比C语言的字符串：</p> <ul><li>SDS可以在O(1)时间获取字符串长度；</li> <li>二进制安全，SDS不需要用&quot;\0&quot;字符来标识字符串结尾，通过len成员变量来记录长度，所以可存储包含 &quot;\0&quot;的数据。</li> <li>SDS先判断空间是否满足要求，若是空间不够，就会进行相应的空间扩展，所以不会出现缓冲区溢出的情况</li> <li>采用预分配冗余空间的方式来减少内存的频繁分配。预分配原则：当修改字符串后的长度len小于1MB，就会预分配和len一样长度的空间，即len=free；若是len大于1MB，free分配的空间大小就为1MB。</li></ul> <p><strong>应用场景：</strong></p> <ul><li>常规计数：Redis处理命令是单线程，所以执行命令的过程是原子的，因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量等等。</li> <li>缓存对象</li></ul> <h4 id="列表list"><a href="#列表list" class="header-anchor">#</a> 列表List</h4> <p>Redis的列表底层是双向链表。list 结构为链表提供了链表头指针 head、链表尾节点 tail、链表节点数量 len、以及可以自定义实现的 dup、free、match 函数。</p> <div class="language-c extra-class"><pre class="language-c"><code><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">list</span> <span class="token punctuation">{</span>
    <span class="token comment">//链表头节点</span>
    listNode <span class="token operator">*</span>head<span class="token punctuation">;</span>
    <span class="token comment">//链表尾节点</span>
    listNode <span class="token operator">*</span>tail<span class="token punctuation">;</span>
    <span class="token comment">//节点值复制函数</span>
    <span class="token keyword">void</span> <span class="token operator">*</span><span class="token punctuation">(</span><span class="token operator">*</span>dup<span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>ptr<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">//节点值释放函数</span>
    <span class="token keyword">void</span> <span class="token punctuation">(</span><span class="token operator">*</span>free<span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>ptr<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">//节点值比较函数</span>
    <span class="token keyword">int</span> <span class="token punctuation">(</span><span class="token operator">*</span>match<span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>ptr<span class="token punctuation">,</span> <span class="token keyword">void</span> <span class="token operator">*</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">//链表节点数量</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> len<span class="token punctuation">;</span>
<span class="token punctuation">}</span> list<span class="token punctuation">;</span>
</code></pre></div><p><img src="https://cdn.nlark.com/yuque/0/2022/png/26499320/1661480318465-b005eb17-7a6d-4bd3-bee2-5faf2dbca0bd.png#clientId=ue0a7919a-f6e9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=191&amp;id=ufcdda756&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=512&amp;originWidth=1449&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=36901&amp;status=done&amp;style=none&amp;taskId=u29743ff0-2e25-4002-9201-b704af55f42&amp;title=&amp;width=540.5" alt="image.png">
Redis 实现的<strong>链表优点</strong>：</p> <ul><li>listNode链表节点的结构里带有 prev 和 next 指针，获取某个节点的前置节点或后置节点的时间复杂度只需O(1)，而且这两个指针都可以指向 NULL，所以链表是无环链表；</li> <li>list 结构因为提供了表头指针 head 和表尾节点 tail，所以获取链表的表头节点和表尾节点的时间复杂度只需O(1)；</li> <li>list 结构因为提供了链表节点数量 len，所以获取链表中的节点数量的时间复杂度只需O(1)；</li> <li>listNode 链表节使用 void* 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此链表节点可以保存各种不同类型的值；</li></ul> <p>**链表缺陷：**链表每个节点之间的内存都是不连续的，意味着无法很好利用CPU缓存。能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问。
Redis3.0中，List 对象在数据量比较少的情况下，会采用「压缩列表」作为底层数据结构的实现，它的优势是节省内存空间，并且是内存紧凑型的数据结构。
<strong>应用场景</strong></p> <ol><li><strong>发布订阅模式</strong>：redis提供主题订阅模式来实现多个消费者的情况。一个客户端可以同时订阅多个频道，例如</li></ol> <p><code>subscribe channel1 channel2</code>。多个客户端可以同时订阅同一个频道（多个消费者，多个生产者）。通过publish channel message命令来向频道中发送信息，在对应的收听客户端能够看到信息。</p> <div class="language-c extra-class"><pre class="language-c"><code>publish channel1 <span class="token string">&quot;hello channel1!&quot;</span>
publish channel2 <span class="token string">&quot;hello channel2~&quot;</span>
</code></pre></div><p>主题订阅模式可以轻松实现简单的消息队列，也可以实现多个消费者和多个生产者的消息传递。但是存在一个问题，消息无法持久化，如果出现网络断开、Redis 宕机等，消息就会被丢弃。简单来说发布订阅 (pub/sub) 可以分发消息，但无法记录历史消息。</p> <ol start="2"><li><strong>使用Stream实现消息队列</strong></li></ol> <p>生产者通过 XADD 命令插入一条消息：</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># * 表示让Redis为插入的数据自动生成一个全局唯一的ID</span>
<span class="token comment"># 往名称为mq的消息队列中插入一条消息，消息的键是name，值是hello</span>
XADD mq * name hello
<span class="token comment"># 插入成功后会返回全局唯一的 ID</span>
<span class="token string">&quot;1654254953808-0&quot;</span>  
</code></pre></div><p>消费者通过 XREAD 命令从消息队列中读取消息时，可以指定一个消息ID，并从<strong>这个消息ID的下一条消息</strong>开始进行读取。使用 XRAED 时设定 block 配置项，实现类似于 BRPOP 的阻塞读取操作。
<strong>基于 Stream 实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？</strong>
Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。</p> <ol start="3"><li><strong>使用List消息队列</strong></li></ol> <p>List 可以使用 LPUSH + RPOP （或者RPUSH+LPOP）命令实现消息队列。</p> <ul><li>生产者使用 LPUSH key value[value...] 将消息插入到队列的头部，如果key不存在则会创建一个空的队列再插入消息。</li> <li>消费者使用RPOP key依次读取队列的消息，先进先出。</li></ul> <p>在生产者往List中写入数据时，List并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用RPOP命令（比如使用一个while(1)循环）。如果有新消息写入，RPOP命令就会返回结果，否则，RPOP命令返回空值，再继续循环。这就会导致消费者程序的 CPU 一直消耗在执行 RPOP 命令上，带来不必要的性能损失。
为了解决这个问题，Redis提供了 BRPOP 命令。BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据。和消费者程序自己不停地调用RPOP命令相比，这种方式能节省CPU开销。
<strong>Redis中用来执行命令处理数据的线程只有一个，</strong><code>**brpop**</code><strong>和</strong><code>**blpop**</code>**这种阻塞命令如何实现的呢？
**redis在blpop命令处理过程时，首先会去查找key对应的list，如果存在，则pop出数据响应给客户端。否则将对应的key push到blocking_keys数据结构当中，对应的value是被阻塞的client。当下次push命令发出时，服务器检查blocking_keys当中是否存在对应的key，如果存在，则将key添加到ready_keys链表当中，同时将value插入链表当中并响应客户端。如果不存在，到时间自动返回。总结来讲，Redis就是使用事件循环和两个链表结构<code>reday_keys</code>和<code>blocking_keys</code>来处理阻塞事件的。
<strong>如何保证消息可靠性？</strong>
List类型提供了BRPOPLPUSH命令，这个命令的作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存。如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。</p> <h4 id="哈希hash"><a href="#哈希hash" class="header-anchor">#</a> 哈希Hash</h4> <p>哈希表是一种保存键值对（key-value）的数据结构。哈希表中的每一个key都是独一无二的，程序可以根据key查找到与之关联的 value，或者通过key来更新value，又或者根据key来删除整个key-value等等。
哈希表优点在于，它能以 O(1) 的复杂度快速查询数据。因为哈希表实际上是数组，通过Hash函数计算key的Hash值，就能定位数据在表中的位置。在哈希表大小固定的情况下，随着数据不断增多，那么哈希冲突的可能性也会越高。Redis采用了「链式哈希」来解决哈希冲突，在不扩容哈希表的前提下，将具有相同哈希值的数据串起来，形成链表，以便这些数据在表中仍然可以被查询到。
Redis 的哈希表结构如下：</p> <div class="language-c extra-class"><pre class="language-c"><code><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">dictht</span> <span class="token punctuation">{</span>
    <span class="token comment">//哈希表数组</span>
    dictEntry <span class="token operator">*</span><span class="token operator">*</span>table<span class="token punctuation">;</span>
    <span class="token comment">//哈希表大小</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> size<span class="token punctuation">;</span>  
    <span class="token comment">//哈希表大小掩码，用于计算索引值</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> sizemask<span class="token punctuation">;</span>
    <span class="token comment">//该哈希表已有的节点数量</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> used<span class="token punctuation">;</span>
<span class="token punctuation">}</span> dictht<span class="token punctuation">;</span>
</code></pre></div><p>哈希表是一个数组（dictEntry **table），数组中每个元素都是指向一个哈希表节点结构（dictEntry）的指针；dictEntry结构里存放了key和value 指针，key指针指向String对象，value指针可以指向 String 对象，也可以指向集合类型的对象。</p> <div class="language-c extra-class"><pre class="language-c"><code><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">dictEntry</span> <span class="token punctuation">{</span>
    <span class="token comment">//键值对中的键</span>
    <span class="token keyword">void</span> <span class="token operator">*</span>key<span class="token punctuation">;</span>
    <span class="token comment">//键值对中的值</span>
    <span class="token keyword">union</span> <span class="token punctuation">{</span>
        <span class="token keyword">void</span> <span class="token operator">*</span>val<span class="token punctuation">;</span>
        <span class="token class-name">uint64_t</span> u64<span class="token punctuation">;</span>
        <span class="token class-name">int64_t</span> s64<span class="token punctuation">;</span>
        <span class="token keyword">double</span> d<span class="token punctuation">;</span>
    <span class="token punctuation">}</span> v<span class="token punctuation">;</span>
    <span class="token comment">//指向下一个哈希表节点，形成链表</span>
    <span class="token keyword">struct</span> <span class="token class-name">dictEntry</span> <span class="token operator">*</span>next<span class="token punctuation">;</span>
<span class="token punctuation">}</span> dictEntry<span class="token punctuation">;</span>
</code></pre></div><p>dictEntry还包含了指向下一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对链接起来，以此来解决哈希冲突的问题。但是随着链表长度的增加，查询这一位置上的数据的耗时就会增加，时间复杂度是O(n)。
dictEntry 结构中的值v是一个「联合体 v」定义的，它可以是一个指向实际值的指针，或者是一个无符号/有符号的64位整数或double 类的值。这么当值v是整数或浮点数时，就可以将值的数据内嵌在 dictEntry 结构里，无需再用一个指针指向实际的值，从而节省了内存空间。
**应用场景：**缓存对象：Hash 类型的 （key，field， value）的结构与对象的（对象id，属性，值）的结构相似，可以用来存储对象。一般对象用 String + Json 存储，对象中某些频繁变化的属性可以考虑抽出来用 Hash 类型存储。</p> <h4 id="rehash和渐进式rehash"><a href="#rehash和渐进式rehash" class="header-anchor">#</a> rehash和渐进式rehash</h4> <p>Redis 定义一个 dict 结构体，这个结构体里定义了两个哈希表，用于rehash操作。</p> <div class="language-c extra-class"><pre class="language-c"><code><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">dict</span> <span class="token punctuation">{</span>
    …
    <span class="token comment">//两个Hash表，交替使用，用于rehash操作</span>
    dictht ht<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span> 
    …
<span class="token punctuation">}</span> dict<span class="token punctuation">;</span>
</code></pre></div><p>在正常服务请求阶段，插入的数据，都会写入到「哈希表1」，此时的「哈希表2」 并没有被分配空间。
随着数据的增多，当满足以下条件时会触发rehash操作。其中，负载因子=哈希表已保存节点数量/哈希表大小。</p> <ul><li>当负载因子大于等于1 ，并且Redis没有执行bgsave命令或者 bgrewiteaof 命令，也就是没有执行RDB快照或没有进行 AOF重写的时候，就会进行rehash操作。</li> <li>当负载因子大于等于5时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB快照或AOF重写，都会强制进行 rehash操作。</li></ul> <p><strong>rehash操作过程：</strong></p> <ul><li>给哈希表2分配空间，一般会比哈希表1大2倍；</li> <li>将哈希表1的数据迁移到哈希表2中；</li> <li>迁移完成后，哈希表1的空间会被释放，并把哈希表2设置为哈希表1，然后在哈希表 2新创建一个空白的哈希表，为下次 rehash做准备。</li></ul> <p>在数据迁移过程中，如果哈希表1的数据量非常大，那么在迁移至哈希表2的时候，因为会涉及大量的数据拷贝，影响Redis性能。
<img src="https://cdn.nlark.com/yuque/0/2022/png/26499320/1661483335537-3832f32f-695d-4034-8fed-b7ac80a63285.png#clientId=ue0a7919a-f6e9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;height=262&amp;id=hYKiX&amp;originHeight=699&amp;originWidth=1502&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uf504af20-655a-472e-a78a-64118cdb3f0&amp;title=&amp;width=563" alt=""> <strong>渐进式rehash</strong>也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。步骤如下：</p> <ul><li>给哈希表2分配空间；</li> <li>在rehash进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将哈希表1中索引位置上的所有 key-value 迁移到哈希表2上；</li> <li>随着处理客户端发起的哈希表操作请求数量越多，最终会把哈希表1的所有 key-value 迁移到哈希表2，从而完成 rehash操作。
这样就巧妙地把一次性大量数据迁移工作的开销，分摊到了多次处理请求的过程中，避免了一次性 rehash 的耗时操作。</li></ul> <p>在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。</p> <ul><li>查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到；</li> <li>新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表</li></ul> <h4 id="集合set"><a href="#集合set" class="header-anchor">#</a> 集合Set</h4> <p>**底层实现：**整数集合是 Set 对象的底层实现之一。当一个 Set 对象只包含整数值元素，并且元素数量不大时，就会使用整数集这个数据结构作为底层实现。
<strong>应用场景：</strong></p> <ul><li>点赞：Set 类型可以保证一个用户只能点一个赞，这里举例子一个场景，key 是文章id，value 是用户id。</li> <li>共同关注：Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。key 可以是用户id，value 则是已关注的公众号的id。</li> <li>抽奖活动：存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次。
集合是无序、不可重复、支持并交差等操作。注意：Set的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致Redis实例阻塞。</li></ul> <h4 id="有序集合zset"><a href="#有序集合zset" class="header-anchor">#</a> 有序集合Zset</h4> <p>Zset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值）。对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序结合的元素值，一个是排序值。
<strong>Zset的底层数据结构是由压缩列表或跳表实现的：</strong></p> <ul><li>如果有序集合的元素个数小于128个，并且每个元素的值小于64字节时，Redis会使用压缩列表作为Zset类型的底层数据结构；</li> <li>如果有序集合的元素不满足上面的条件，Redis会使用跳表作为Zset类型的底层数据结构；</li></ul> <div class="language-c extra-class"><pre class="language-c"><code><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">zset</span> <span class="token punctuation">{</span>
    dict <span class="token operator">*</span>dict<span class="token punctuation">;</span>
    zskiplist <span class="token operator">*</span>zsl<span class="token punctuation">;</span>
<span class="token punctuation">}</span> zset<span class="token punctuation">;</span>
</code></pre></div><p><strong>应用场景：</strong></p> <ul><li>排行榜：zset用来存粉丝列表，value 值是粉丝的用户 ID，score 是关注时间。我们可以对粉丝列表按关注时间进行排序。zset 还可以用来存储学生的成绩，value 值是学生的 ID，score 是他的考试成绩。我们可以对成绩按分数进行排序就可以得到他的名次。</li> <li>电话、姓名排序：使用有序集合的 ZRANGEBYLEX 或 ZREVRANGEBYLEX 可以帮助我们实现电话号码或姓名的排序</li></ul> <h5 id="压缩列表"><a href="#压缩列表" class="header-anchor">#</a> 压缩列表</h5> <p>压缩列表是一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。
<img src="https://cdn.nlark.com/yuque/0/2022/png/26499320/1661484072961-e72b795a-fc2b-46f2-b215-a293ef7a5908.png#clientId=ue0a7919a-f6e9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=151&amp;id=KZh4v&amp;name=image.png&amp;originHeight=302&amp;originWidth=962&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=26945&amp;status=done&amp;style=none&amp;taskId=u1a373e24-f8ab-4d06-9c93-00d22814d7f&amp;title=&amp;width=481" alt="image.png">
压缩列表数据结构头部有三个字段：</p> <ul><li>zlbytes，记录整个压缩列表占用的内存字节数；</li> <li>zltail，记录压缩列表「尾部」节点距离起始地址有多少字节，也就是列表尾的偏移量；</li> <li>zllen，记录压缩列表包含的节点数量；</li></ul> <p>可以通过头部三个字段的长度直接定位第一个节点和最后一个节点。对于其他元素，只能逐个查找，复杂度是O(N)，因此压缩列表不适合保存过多的元素。尾部有一个zlend字段，标记压缩列表的结束点，固定值 0xFF（十进制255）。
压缩列表节点包含三部分内容：</p> <ul><li>prevlen记录了「前一个节点」的长度；</li> <li>encoding记录了当前节点实际数据的类型以及长度；</li> <li>data记录了当前节点的实际数据；</li></ul> <p>当往压缩列表中插入数据时，压缩列表会根据数据是字符串还是整数，以及数据的大小，使用不同空间大小的 prevlen 和 encoding 保存信息，这种根据数据大小和类型进行不同的空间大小分配的设计思想，可以大大节省内存。压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降。</p> <h5 id="跳表"><a href="#跳表" class="header-anchor">#</a> 跳表</h5> <p>跳表是在有序链表基础上改进而来的一种多层有序链表。在一个有序链表中，如果我们要查找某个数据，那么需要从头开始逐个进行比较，直到找到包含数据的那个节点或者这个数据不存在，时间复杂度为O(n)。
假如让链表中的每相邻两个节点再增加一个指针，指向下下个节点，这样所有新增加的指针连成了一个新的链表，但它包含的节点个数只有原来的一半。现在我们查找数据的时候，先沿着上层这个新链表进行查找。当碰到比待查数据大的节点时，再回到第一层原始链表中进行查找。在上层链表查找过程中，需要比较的节点数大约只有原来的一半，这样就提高了查询速度。
跳表思想是除了底层第一层链表外，向上产生若干层稀疏的链表，这些链表里面的指针故意跳过了一些节点，而且越高层的链表跳过的节点越多。这就我们在查找数据时，先在高层链表中进行查找，然后逐层降低，最终降到第1层链表来精确地定位数据位置。在这个过程中，我们跳过了一些节点，加快了查找速度，提高了查询效率。
跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。</p> <div class="language-c extra-class"><pre class="language-c"><code><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">zskiplistNode</span> <span class="token punctuation">{</span>
    <span class="token comment">//Zset 对象的元素值</span>
    sds ele<span class="token punctuation">;</span>
    <span class="token comment">//元素权重值</span>
    <span class="token keyword">double</span> score<span class="token punctuation">;</span>
    <span class="token comment">//后向指针</span>
    <span class="token keyword">struct</span> <span class="token class-name">zskiplistNode</span> <span class="token operator">*</span>backward<span class="token punctuation">;</span>
    <span class="token comment">//节点的level数组，保存每层上的前向指针和跨度</span>
    <span class="token keyword">struct</span> <span class="token class-name">zskiplistLevel</span> <span class="token punctuation">{</span>
        <span class="token keyword">struct</span> <span class="token class-name">zskiplistNode</span> <span class="token operator">*</span>forward<span class="token punctuation">;</span>
        <span class="token keyword">unsigned</span> <span class="token keyword">long</span> span<span class="token punctuation">;</span>
    <span class="token punctuation">}</span> level<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> zskiplistNode<span class="token punctuation">;</span>
</code></pre></div><p>在跳表节点中，用sds类型的ele变量保存元素，double类型的score变量元素的权重。每个跳表节点还有一个后向指针，指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，这样倒序查找时很方便。
跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的zskiplistLevel 结构体类型的 level 数组。
level 数组中的每一个元素代表跳表的一层，也就是由 zskiplistLevel 结构体表示，比如 leve[0] 就表示第一层，leve[1] 就表示第二层。zskiplistLevel 结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度用来记录两个节点之间的距离。
<img src="https://cdn.nlark.com/yuque/0/2022/png/26499320/1661484415917-28b0d6fb-b7b8-49fa-bf3b-a3279baaebc6.png#clientId=ue0a7919a-f6e9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=159&amp;id=u591a590b&amp;name=image.png&amp;originHeight=317&amp;originWidth=1947&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=55854&amp;status=done&amp;style=none&amp;taskId=u2577bda5-c9ba-4f38-aa80-50db51ae5e7&amp;title=&amp;width=973.5" alt="image.png"></p> <h4 id="三种特殊的数据类型"><a href="#三种特殊的数据类型" class="header-anchor">#</a> 三种特殊的数据类型</h4> <ul><li>HyperLogLog，用于基数统计，结果不是精确的，但是每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64个不同元素的基数。</li> <li>地理位置GEO，存储地理位置信息，并对存储的信息进行操作</li> <li>位图bitmap，本质上是字符串，按位存储信息，用于统计签到次数，日活等等</li></ul> <h3 id="持久化策略"><a href="#持久化策略" class="header-anchor">#</a> 持久化策略</h3> <p><strong>RDB持久化</strong>是指在指定的时间间隔内，执行指定次数的写操作，将内存中的数据快照写入磁盘中，它是Redis默认的持久化方式。执行完操作后，在指定目录下会生成一个dump.rdb文件，Redis 重启的时候，通过加载dump.rdb文件来恢复数据。
bgsave是主流的触发 RDB 持久化的方式，执行过程如下：</p> <ol><li>执行BGSAVE命令</li> <li>Redis 父进程判断当前是否存在正在执行的子进程，如果存在，BGSAVE命令直接返回。</li> <li>父进程执行fork操作创建子进程，fork操作过程中父进程会阻塞。</li> <li>父进程fork完成后，父进程继续接收并处理客户端的请求**，而**子进程开始将内存中的数据写进硬盘的临时文件；</li> <li>当子进程写完所有数据后会用该临时文件替换旧的 RDB 文件。</li></ol> <p>Redis启动时会读取RDB快照文件，将数据从硬盘载入内存。通过 RDB 方式的持久化，一旦Redis异常退出，就会丢失最近一次持久化以后更改的数据。RDB持久化存在问题是不能实时持久化/秒级持久化、新老版本存在RDB格式兼容问题。
<img src="https://cdn.nlark.com/yuque/0/2022/png/26499320/1661484535430-5d9ecfcd-41f7-4b2b-9366-eb88d05b9756.png#clientId=ue0a7919a-f6e9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=282&amp;id=uf8bebc73&amp;name=image.png&amp;originHeight=848&amp;originWidth=1238&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=332322&amp;status=done&amp;style=none&amp;taskId=ud35afa86-c746-4c99-8691-08631c196fd&amp;title=&amp;width=412" alt="image.png"> <strong>AOF持久化</strong>
AOF（append only file）持久化，采用日志的形式来记录每个写操作，追加到文件中，重启时再重新执行AOF文件中的命令来恢复数据。它主要解决数据持久化的实时性问题。默认是不开启的。</p> <ol><li>所有的写入命令会追加到 AOP 缓冲区中。</li> <li>AOF 缓冲区根据对应的策略向硬盘同步。</li> <li>随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩文件体积的目的。AOF文件重写是把Redis进程内的数据转化为写命令同步到新AOF文件的过程。</li> <li>当 Redis 服务器重启时，可以加载 AOF 文件进行数据恢复。</li></ol> <p>AOF的缺点是AOF记录的内容越多，文件越大，数据恢复变慢。
<img src="https://cdn.nlark.com/yuque/0/2022/png/26499320/1661484630486-c56ace5f-e911-48e0-9ac1-be0fa0484adf.png#clientId=ue0a7919a-f6e9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=350&amp;id=u24621c9a&amp;name=image.png&amp;originHeight=700&amp;originWidth=524&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=149138&amp;status=done&amp;style=none&amp;taskId=u19e7c554-d8bd-4c7c-907c-b75c9bfe698&amp;title=&amp;width=262" alt="image.png"></p> <h3 id="redis和db的数据一致性问题"><a href="#redis和db的数据一致性问题" class="header-anchor">#</a> Redis和DB的数据一致性问题</h3> <h4 id="旁路缓存"><a href="#旁路缓存" class="header-anchor">#</a> 旁路缓存</h4> <p>旁路缓冲适合读请求比较多的情景。
<strong>对于写数据：先更新DB，然后直接删除缓存。</strong></p> <ol><li>**写数据过程中，可以先删除cache后更新DB吗？**肯定是不行的，会造成数据库和缓存数据不一致问题。比如请求1先把cache中的A数据删除—&gt;请求2从DB中读取数据—&gt;请求1再把DB中的A数据更新。</li> <li>**写数据过程中，先更新DB后删除cache就没有问题了吗?**理论上来说还是可能会出现数据不一致的问题，不过概率非常小，因为缓存写入速度比数据写入速度快很多！比如：请求1从DB读数据A—&gt;请求2写更新数据A到数据库并删除缓存中的A数据—&gt;请求1将数据A写入cache。</li></ol> <p>**对于读数据：**从cache中读取数据，读取到就直接返回。读取不到就去DB中读，写入到缓存返回数据。</p> <ol><li><strong>对于首次请求数据一定不在cache的问题</strong>，可以将热点数据提取放到cache中</li> <li><strong>写操作频繁的话导致cache中的数据会被频繁删除，影响命中率？</strong>
解决方法：对于数据库和缓存数据强一致性场景：更新DB同时更新cache。不过需要加一个锁/分布式锁来保证更新cache的时不存在线程安全问题</li> <li><strong>对于短暂地允许DB和cache不一致的场景</strong>：更新DB时同样更新cache，但是给缓存加一个比较短的过期时间，这也就可以保证即使数据不一致的话影响也比较小</li></ol> <h4 id="读写穿透"><a href="#读写穿透" class="header-anchor">#</a> 读写穿透</h4> <p>读写穿透中服务端把cache视为主要数据存储，从中读取数据并将数据写入其中。cache服务负责将此数据读取和写入DB，从而减轻应用程序的职责。
<strong>对于写数据</strong>：先查cache，cache不存在，直接更新DB- cache中存在，则先更新cache，然后cache服务自己更新DB。
<strong>对于读数据</strong>：从cache中读取数据，读取到就直接返回。读取不到就去DB中读，则先从DB加载写入到缓存返回数据。</p> <h4 id="异步缓存"><a href="#异步缓存" class="header-anchor">#</a> 异步缓存</h4> <p>异步缓存写入和读写穿透很相似，两者都是由cache服务来负责cache和DB的读写。
两者最大的不同点是：读写穿透是同步更新DB和cache，而异步缓存写入则是只更新cache，不直接更新DB，而是改为异步批量的方式更新DB。很明显，这种方式对数据一致性带来了更大的挑战，比如cache数据可能还没异步更新DB，cache服务可能就挂了。
这种策略在我们平时开发过程中也非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL的InnoDB Buffer Pool机制都用到了这种策略。
异步缓存写入的写性能非常高，非常适合写数据经常变化又对数据一致性要求没那么高的场景下使用，比如浏览量、点赞量等。</p> <h3 id="缓存问题"><a href="#缓存问题" class="header-anchor">#</a> 缓存问题</h3> <p>**缓存雪崩：**当大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃。
<strong>缓存击穿</strong>：如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是缓存击穿的问题。解决方法：</p> <ul><li>采用互斥锁，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</li> <li>不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；</li></ul> <p>**缓存穿透：**当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。
<img src="https://cdn.nlark.com/yuque/0/2022/png/26499320/1661486163530-7d412512-5396-437d-b5e9-be2efd0a7d3b.png#clientId=ue0a7919a-f6e9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=311&amp;id=oKO9D&amp;name=image.png&amp;originHeight=622&amp;originWidth=1080&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=204754&amp;status=done&amp;style=none&amp;taskId=u6cc1539a-0d6d-47f9-b040-613683189a7&amp;title=&amp;width=540" alt="image.png"></p> <h3 id="过期键的删除策略"><a href="#过期键的删除策略" class="header-anchor">#</a> 过期键的删除策略</h3> <p>每当设置一个键的过期时间时，redis就会从过期字典中检测是否存在，存在则获取过期时间，然后用过期时间和当前系统时间进行比对，比系统时间大则没有过期，反之过期。redis过期键的删除策略是惰性删除和定期删除两种策略配合使用</p> <div class="language-bash extra-class"><pre class="language-bash"><code>expire key <span class="token function">time</span> // key的过期时间是time秒
</code></pre></div><p>**定时删除：**设置过期时间，创建定时器，定时器到了过期时间后立即执行删除操作。对内存优化，用完就删了。对cpu不友好，过期键多的时候，删除会占cpu时间，对服务器响应和吞吐量有影响。
**惰性删除：**设置过期时间不管他，等用的时候看是否过期了，过期就执行删除。对cpu友好。对内存不友好，可能造成内存泄漏。
**定期删除：**每隔一段时间对一些key检查，删除里面过期的key。
优点：</p> <ul><li>可以限制删除操作执行的时长和频率来减少删除操作对cpu的影响</li> <li>定期删除也能有效的释放过期键占用的内存</li></ul> <p>缺点：</p> <ul><li>难以确定删除操作的时长和频，太频繁和定时删除一样了，太少和惰性删除一样了。</li> <li>再获取某个键时，某个键的过期时间到了但还没执行定期删除，那么就会返回这个键的值，这是业务不能忍受的错误。</li></ul> <h3 id="内存淘汰策略"><a href="#内存淘汰策略" class="header-anchor">#</a> 内存淘汰策略</h3> <p>当Redis的内存超过最大允许的内存之后，Redis 会触发内存淘汰策略，删除一些不常用的数据，以保证Redis服务器正常运行。
<strong>Redisv4.0前提供 6 种数据淘汰策略</strong>：</p> <ul><li><strong>volatile-lru</strong>：LRU（Least Recently Used），最近使用。利用LRU算法移除设置了过期时间的key</li> <li><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，从数据集中移除最近最少使用的key</li> <li><strong>volatile-ttl</strong>：从已设置过期时间的数据集中挑选将要过期的数据淘汰</li> <li><strong>volatile-random</strong>：从已设置过期时间的数据集中任意选择数据淘汰</li> <li><strong>allkeys-random</strong>：从数据集中任意选择数据淘汰</li> <li><strong>no-eviction</strong>：禁止删除数据，当内存不足以容纳新写入数据时，新写入操作会报错
<strong>Redisv4.0后增加以下两种</strong>：</li> <li><strong>volatile-lfu</strong>：LFU，Least Frequently Used，最少使用，从已设置过期时间的数据集中挑选最不经常使用的数据淘汰。</li> <li><strong>allkeys-lfu</strong>：当内存不足以容纳新写入数据时，从数据集中移除最不经常使用的key。
<strong>内存淘汰策略可以通过配置文件来修改</strong>，相应的配置项是maxmemory-policy，默认配置是noeviction。</li></ul> <h3 id="分布式锁"><a href="#分布式锁" class="header-anchor">#</a> 分布式锁</h3> <p>SET 命令有个 NX 参数可以实现「key不存在才插入」，可以用它来实现分布式锁。如果 key 不存在，则显示插入成功，可以用来表示加锁成功；如果 key 存在，则会显示插入失败，可以用来表示加锁失败。
一般而言，还会对分布式锁加上过期时间，分布式锁命令如下：</p> <div class="language-bash extra-class"><pre class="language-bash"><code>// NX代表只在lock_ key不存在时，才对lock_ key进行设置操作；
// PX <span class="token number">10000</span>表示设置lock_ key的过期时间为10s，这是为了避免客户端发生异常而无法释放锁。
SET lock_key unique_value NX PX <span class="token number">10000</span>
</code></pre></div><p>解锁的过程就是将 lock_key 键删除，但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以解锁的时候，先判断锁的 unique_value是否为加锁客户端，是的话，才将lock_key键删除。</p> <div class="language-bash extra-class"><pre class="language-bash"><code>// 释放锁时，先比较unique_value是否相等，避免锁的误释放
<span class="token keyword">if</span> redis.call<span class="token punctuation">(</span><span class="token string">&quot;get&quot;</span>,KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> ARGV<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">then</span>
<span class="token builtin class-name">return</span> redis.call<span class="token punctuation">(</span><span class="token string">&quot;del&quot;</span>,KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">else</span>
<span class="token builtin class-name">return</span> <span class="token number">0</span>
end
</code></pre></div><p>解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。
这样做存在一个问题，如果规定时间内该线程并没有结束，却释放了锁怎么办？
可以使用一个守护线程，定时检查任务是否完成，如果没有完成，为锁续命</p> <div class="language-bash extra-class"><pre class="language-bash"><code>// 为锁续命3秒
expire lock <span class="token number">3</span>
</code></pre></div><p>redis分布式锁遇到的问题及解决方法：</p> <ul><li>死锁：设置过期时间</li> <li>过期时间评估不好，锁提前过期：守护线程，自动续期</li> <li>锁被别人释放：锁写入唯一标识，释放锁先检查标识，再释放</li></ul> <p>上面的实现方式还存在一个问题，就是如果设置了锁之后，主节点宕机，而从节点恰好也没有同步到这个锁，那么就会导致锁丢失的问题，引起线程安全问题。</p> <h5 id="redlock-红锁"><a href="#redlock-红锁" class="header-anchor">#</a> RedLock(红锁)</h5> <p>RedLock加锁过程：</p> <ol><li>客户端先获取「当前系统时间戳T1」</li> <li>客户端依次向<strong>多个</strong>(至少5个) Redis 实例发起加锁请求，且每个请求都会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（网络超时、锁被其它人持有等异常情况），就立即向下一个 Redis 实例申请加锁</li> <li>如果客户端在<strong>大多数</strong>（n / 2 + 1，这里为3） Redis 实例加锁成功，则再次获取「当前系统时间戳T2」，如果 T2 - T1 &lt; 锁的过期时间，认为客户端加锁成功，否则认为加锁失败</li> <li>加锁成功，去操作共享资源（如修改 MySQL 某一行或发起一个 API 请求）</li> <li>加锁失败，向<strong>全部节点</strong>发起释放锁请求（Lua 脚本释放锁）。</li></ol> <p>**为什么要在多个实例上加锁？**本质上是为了「容错」，部分实例异常宕机，剩余的实例加锁成功，整个锁服务依旧可用。
**为什么大多数加锁成功，才算成功？**在分布式系统中，总会出现异常节点，如果只存在「故障」节点，只要大多数节点正常，那么整个系统依旧是可以提供正确服务的。
**为什么加锁成功后，还要计算加锁的累计耗时？**因为操作的是多个节点，所以耗时肯定会比操作单个实例耗时更长，而且网络可能存在延迟、丢包、超时等情况发生，网络请求越多，异常发生的概率就越大。所以，即使大多数节点加锁成功，但如果加锁的累计耗时已经超过了锁的过期时间，那此时有些实例上的锁可能已经失效了，这个锁就没有意义了。
**为什么释放锁，要操作所有节点？**防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁</p> <h5 id="zookeeper实现分布式锁"><a href="#zookeeper实现分布式锁" class="header-anchor">#</a> Zookeeper实现分布式锁</h5> <p>zk是一个小型文件管理系统。
临时节点：客户端1尝试创建临时节点znode，此时创建成功了就获取了这个锁；这个时候客户端2来创建锁会失败，只能注册个监听器监听这个锁。释放锁就是删除这个 znode，一旦释放掉就会通知客户端，然后有一个等待着的客户端就可以再次重新加锁。
顺序节点：多个客户端排队获取锁，最前面的客户端先获取到锁执行任务，然后释放锁；后面的每个客户端都会去监听排在自己前面的那个客户端创建的node 。一旦某个客户端释放了锁，后面的客户端就会收到 ZooKeeper 的通知，自己就获取到了锁，就可以执行代码了。
存在问题：zk 依靠 session 定期的心跳来维持客户端，如果客户端进入长时间的 GC，可能会导致 zk 认为客户端宕机而释放锁，让其他的客户端获取锁，但是客户端在 GC 恢复后，会认为自己还持有锁，从而可能出现多个客户端同时获取到锁的情形。可以通过 JVM 调优，尽量避免长时间 GC 的情况发生。</p> <h3 id="部署模式"><a href="#部署模式" class="header-anchor">#</a> 部署模式</h3> <p>**单机模式：**只使用一个redis服务器。特点就是简单，但存在问题是内存容量有限、处理能力有限、无法高可用。
<img src="https://cdn.nlark.com/yuque/0/2022/png/26499320/1661484689455-44c56b23-e505-4130-a222-722d10677200.png#clientId=ue0a7919a-f6e9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;from=paste&amp;height=161&amp;id=u7eadc720&amp;name=image.png&amp;originHeight=241&amp;originWidth=426&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;size=54583&amp;status=done&amp;style=none&amp;taskId=uff4eaaaa-3979-488d-a3cb-7a46ce881f1&amp;title=&amp;width=284" alt="image.png">
**主从复制模式：**一主多从（读写分离）主机负责写操作，并将数据同步给其他从节点，从机负责读操作，从而实现
高并发。特点是将读的压力从主库转到从库。
<img src="https://cdn.nlark.com/yuque/0/2022/png/26499320/1661484731145-3ebb7a2d-777d-4101-bd2b-b0492622c7d7.png#clientId=ue0a7919a-f6e9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;height=227&amp;id=atzas&amp;originHeight=355&amp;originWidth=462&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u7f68773b-cf7a-4cae-b400-89bc4f15e24&amp;title=&amp;width=296" alt="">
存在问题：无法保证高可用。没有解决主库写的压力。
<strong>哨兵模式</strong>是建立在主从模式之上。可以监控主从服务器，并在主服务器下线时自动进行故障转移。
<img src="https://cdn.nlark.com/yuque/0/2022/png/26499320/1661484816093-f6852deb-ed13-4b0d-b478-59d8598d37f4.png#clientId=ue0a7919a-f6e9-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;crop=1&amp;height=228&amp;id=gDnd5&amp;originHeight=401&amp;originWidth=438&amp;originalType=binary&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ucd3d3c49-0946-4f6c-87de-7907b7d2f00&amp;title=&amp;width=249" alt=""></p> <ul><li>监控： 不断检查主服务器和从服务器的工作状态是否正常</li> <li>提醒：当被监控的某个服务器出现问题时，哨兵 可以通过API向管理员或者其他的应用程序发送通知。</li> <li>自动故障迁移：当一个主服务器不能正常工作时，哨兵会开始自动故障迁移操作。</li></ul> <p>特点：</p> <ol><li>可以保证高可用性</li> <li>可以监控各个节点</li> <li>自动故障迁移</li></ol> <p>**问题：**没有解决主服务器的写压力问题</p></div></section> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">更新时间: </span> <span class="time">10/16/2022, 1:36:19 PM</span></div></footer> <!----> <div class="comments-wrapper"><!----></div></main></div> <!----></div> <ul class="sub-sidebar sub-sidebar-wrapper" style="width:0;" data-v-b57cc07c data-v-7dd95ae2></ul></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div></div></div>
    <script src="/vblog/assets/js/app.b753b481.js" defer></script><script src="/vblog/assets/js/3.a14ab248.js" defer></script><script src="/vblog/assets/js/1.82212610.js" defer></script><script src="/vblog/assets/js/21.bbedd2e8.js" defer></script>
  </body>
</html>
